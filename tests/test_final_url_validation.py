#!/usr/bin/env python3
"""Final test to verify URL validation fix is working correctly."""

import sys
sys.path.insert(0, '/home/krashnicov/crawl4aimcp/src')

from utils.validation import validate_urls_for_crawling


def test_original_error_scenario():
    """Test the exact scenario from the original error."""
    print("Testing Original Error Scenario")
    print("=" * 60)
    
    # The exact URLs from the error log
    problematic_urls = [
        "https://example.com",
        ".../help/example-domains"  # This was truncated in the logs
    ]
    
    print(f"Input URLs: {problematic_urls}")
    print("\nValidation Result:")
    
    result = validate_urls_for_crawling(problematic_urls)
    
    if result["valid"]:
        print("‚úó UNEXPECTED: Validation passed (should have failed)")
        print(f"  Output URLs: {result['urls']}")
    else:
        print("‚úì EXPECTED: Validation correctly rejected invalid URLs")
        print(f"  Error: {result['error']}")
        if result.get("invalid_urls"):
            print(f"  Invalid URLs: {result['invalid_urls']}")
        if result.get("valid_urls"):
            print(f"  Valid URLs that could be processed: {result['valid_urls']}")
    
    print("\n" + "=" * 60)
    
    # Test if we're preventing the crawl4ai error
    print("\nVerifying crawl4ai protection:")
    
    if not result["valid"]:
        print("‚úì crawl4ai will NOT receive invalid URLs")
        print("  The ValueError from crawl4ai is prevented!")
    else:
        print("‚úó crawl4ai would receive URLs and might fail")
    
    print("\n" + "=" * 60)
    return not result["valid"]  # Should return True (validation should fail)


def test_comprehensive_scenarios():
    """Test various URL scenarios to ensure robustness."""
    print("\nComprehensive URL Validation Tests")
    print("=" * 60)
    
    test_cases = [
        {
            "name": "Valid HTTPS URLs",
            "urls": ["https://example.com", "https://www.iana.org/help/example-domains"],
            "should_pass": True
        },
        {
            "name": "Truncated URLs (ellipsis)",
            "urls": [".../path/to/page", "...example.com"],
            "should_pass": False
        },
        {
            "name": "Mixed valid and truncated",
            "urls": ["https://valid.com", ".../truncated/path"],
            "should_pass": False
        },
        {
            "name": "URLs without protocol",
            "urls": ["example.com", "www.example.org"],
            "should_pass": False
        },
        {
            "name": "Invalid protocols",
            "urls": ["ftp://example.com", "ssh://server.com"],
            "should_pass": False
        },
        {
            "name": "File and raw protocols (valid for crawl4ai)",
            "urls": ["file:///path/to/file.html", "raw:Some raw content"],
            "should_pass": True
        }
    ]
    
    all_passed = True
    
    for test in test_cases:
        print(f"\nTest: {test['name']}")
        print(f"URLs: {test['urls']}")
        
        result = validate_urls_for_crawling(test["urls"])
        
        if test["should_pass"]:
            if result["valid"]:
                print("‚úì PASS: Validation correctly accepted valid URLs")
            else:
                print(f"‚úó FAIL: Should have passed but got error: {result['error']}")
                all_passed = False
        else:
            if not result["valid"]:
                print(f"‚úì PASS: Validation correctly rejected invalid URLs")
                print(f"  Reason: {result['error'][:100]}...")
            else:
                print(f"‚úó FAIL: Should have failed but passed with URLs: {result['urls']}")
                all_passed = False
    
    print("\n" + "=" * 60)
    return all_passed


def main():
    """Run all tests."""
    print("\nüîç URL VALIDATION FIX VERIFICATION")
    print("=" * 60)
    
    # Test the original error scenario
    original_fixed = test_original_error_scenario()
    
    # Test comprehensive scenarios
    comprehensive_passed = test_comprehensive_scenarios()
    
    # Summary
    print("\nüìä TEST SUMMARY")
    print("=" * 60)
    
    if original_fixed:
        print("‚úÖ Original error scenario: FIXED")
        print("   - Truncated URLs are properly detected")
        print("   - Helpful error messages are provided")
        print("   - crawl4ai won't receive invalid URLs")
    else:
        print("‚ùå Original error scenario: NOT FIXED")
    
    if comprehensive_passed:
        print("‚úÖ Comprehensive tests: ALL PASSED")
    else:
        print("‚ùå Comprehensive tests: SOME FAILED")
    
    if original_fixed and comprehensive_passed:
        print("\nüéâ SUCCESS: URL validation is working correctly!")
        print("The crawl4ai error 'URL must start with http://, https://, file://, or raw:' is prevented.")
    else:
        print("\n‚ö†Ô∏è  ATTENTION: Some tests failed. Review the results above.")
    
    print("=" * 60)


if __name__ == "__main__":
    main()